# HiCARN: Super Resolution of Hi-C Data with a Cascading Residual Network

___________________
## Dependencies
HiCARN is written in Python3 and uses the Pytorch module. 
**_Note:_** GPU usage for training and testing is highly recommended.



The following versions are recommended when using HiCARN:
- Python 3.8
- Pytorch 1.9.0
- Numpy 1.21.1
- Scipy 1.7.0
- Pandas 1.3.1
- Scikit-learn 0.15.2
- Matplotlib 3.4.2
- tqdm 4.61.2

___________________

## Data Preprocessing
Click [here](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE63525) to view the GSE62525
GEO accession for Hi-C data from (Rao *et al.* 2014). We used [GM12878](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FCH12%2DLX%5Fintrachromosomal%5Fcontact%5Fmatrices%2Etar%2Egz)
primary intrachromosomal, [K562](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FK562%5Fintrachromosomal%5Fcontact%5Fmatrices%2Etar%2Egz)
intrachromasomal, and [CH12-LX](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FCH12%2DLX%5Fintrachromosomal%5Fcontact%5Fmatrices%2Etar%2Egz)
(mouse) intrachromosomal contact matrices.

Set your root directory as a string in `Data/Arg_Parser.py`. Unzip and open the data in `$root_dir/raw`. A folder with
the cell line name will be created containing contact matrices for all chromosomes for all available resolutions. See
the [README](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FOVERALL%5FREADME%2Ertf)
for further details.

Processed data from our `Data/Example_Data` directory should be placed in `$root_dir/data`. For simplicity, high and
low resolution will be referred to as HR and LR respectively.

Follow the following steps to generate datasets in .npz format:
1. **Read the raw data.** 
   * This will create a new directory `$root_dir/mat/[cell_line_name]` where all chrN_[HR].npz files
will be stored.

```bash
$ python Read_Data.py -c GM12878
```
Required arguments:
* `-c`: Cell line as named in `$root_dir/raw/[cell_line_name]`.

Optional arguments:
* `-hr`: Specified resolution. You can choose from 5kb, 10kb, 25kb, 50kb, 100kb, 250kb, 500kb, and 1mb. Default is 10kb.
* `-q`: Specified map quality. Options are MAPQGE30 and MAPQG0. Default is MAPQGE30.
* `-n`: Normalization. Options are KRnorm, SQRTVCnorm, and VCnorm. Default is KRnorm.

2. **Randomly downsample the data.** This adds downsampled HR data to `$root_dir/mat/[cell_line_name]` as chrN_[LR].npz.

```bash
$ python Data/Downsample.py -hr 10kb -lr 40kb -r 16 -c GM12878
```
All arguments:
* `-hr`: Specified resolution from the previous step. Default is 10kb
* `lr`: Provides a resolution for [LR] in chrN_[LR].npz. Default is 40kb
* `-r`: Downsampling ratio. Default is 16
* `-c`: Cell line name.

3. **Generate train, validation, and test datasets.** 
   * You can set your desired chromosomes for each set in 
   `Data/Arg_Parser.py` within the `set_dict` dictionary. 
   * This specific example will create a file in `$root_dir/data` named 
   hicarn_10kb40kb_c40_s40_b201_nonpool_train.npz. 
   
```bash
$ python Data/Generate.py -hr 10kb -lr 40kb -lrc 100 -s train -chunk 40 -stride 40 -bound 201 -scale 1 -c GM12878
```
All arguments:
* `-hr`: High resolution in chrN_[HR].npz used as a target for training. Default is 10kb.
* `-lr`: Low resolution in chrN_[LR].npz used as training inputs. Default is 40kb.
* `-lrc`: Set the lowest value in the LR matrix. Default is 100.
* `-s`: Dataset to be generated. Options are train, valid, GM12878_test, K562_test, and mESC_test. Default is train.
* `-chunk`: nxn size for each submatrix. Default is 40.
* `-stride`: Set equal to `-chunk`. Default is 40.
* `-bound`: The upper bound of genomic distance. Default is 201.
* `-scale`: Whether to pool input submatrices or not. Default is 1.
* `-c`: That cell line name again...

Congratulations! You now have your datasets. ***Note***: For training, you must have both training and validation 
files present in `$root_dir/data`. 

___________________
## Training

We provide training files for both HiCARN-1 and HiCARN-2. 

To train:

```bash
$ python Train/HiCARN_[1 or 2]_Train.py
```
___________________
## Predicting

We provide pretrained weights for HiCARN and all other compared models. You can also use the weights generated by 
your own trained model. For quick predictions use the following commands below:

1. If predicting with HiCARN-1, HiCARN-2, or DeepHiC:
```bash
$ python Predict/40x40_Predict.py -m hicarn_1 -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -c GM12878
```

2. If predicting with HiCSR, HiCNN, or HiCPlus:
* These models output a 28x28 matrix from a 40x40 input, so the inputs need to be padded to 52x52 so that a 40x40
output is returned.
```bash
$ python Predict/28x28_Predict.py -m hicsr -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -c GM12878
```
All arguments:
* `-m`: Model to predict with. Options are hicarn_1, hicarn_2, deephic, hicsr, hicnn, or hicplus.
* `-lr`: Low resolution to be enhanced. Default is 40kb.
* `-ckpt`: Checkpoint file from either our `Pretrained_weights` or your `$root_dir/checkpoints` directory.
* `-f`: Low resolution file to be enhanced. 
  * Example: `file/location/hicarn_10kb40kb_c40_s40_b201_nonpool_GM12878_test.npz.`
* `-c`: The cell line just one more time.

___________________

If you would like to perform analysis metrics for your predictions use the following commands:

1. If predicting with HiCARN-1, HiCARN-2, or DeepHiC:
```bash
$ python Predict/40x40_Predict_With_Metrics.py -m hicarn_1 -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -c GM12878
```

2. If predicting with HiCSR, HiCNN, or HiCPlus:
```bash
$ python Predict/28x28_Predict_With_Metrics.py -m hicsr -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -c GM12878
```